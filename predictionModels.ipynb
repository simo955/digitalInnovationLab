{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualization library\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0        1       1   0     1        0        6           0           2   \n",
       "1        2       1   0     1        0        0           0           2   \n",
       "2        3       1   0     1        0        1           1           1   \n",
       "3        4       1   0     1        0        2           1           1   \n",
       "4        5       1   0     1        0        3           1           1   \n",
       "\n",
       "       temp     atemp       hum  windspeed   cnt cluster  \n",
       "0  0.344167  0.363625  0.805833   0.160446   985     low  \n",
       "1  0.363478  0.353739  0.696087   0.248539   801     low  \n",
       "2  0.196364  0.189405  0.437273   0.248309  1349     low  \n",
       "3  0.200000  0.212122  0.590435   0.160296  1562     low  \n",
       "4  0.226957  0.229270  0.436957   0.186900  1600     low  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_Preprocessed2.csv\")\n",
    "df=df.drop(['dteday'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test set Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 548\n",
      "Test size 183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols = ['season', 'yr', 'mnth', 'holiday', 'weekday','workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster\n",
    "yReg= df.cnt\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_trainReg, X_testReg, y_trainReg, y_testReg = train_test_split(X, yReg, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#score df is later used for comparison between differen iteration\n",
    "score_df = pd.DataFrame(columns=[\"method\"])\n",
    "\n",
    "\n",
    "def  My_Classifier (X_train, y_train, X_test, y_test,it=0):\n",
    "    col=\"score \"+str(it)\n",
    "    score_df[col]=0.0\n",
    "    maxScore =0\n",
    "    \n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    clf=RandomForestClassifier(n_estimators=1000)\n",
    "    nn = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,), random_state=1)\n",
    "    \n",
    "    #fit\n",
    "    logreg.fit(X_train, y_train)\n",
    "    clf.fit(X_train,y_train)\n",
    "    nn.fit(X_train, y_train)   \n",
    "\n",
    "    #Score\n",
    "    score=logreg.score(X_test,y_test)\n",
    "    score_df.at[0,'method'] = \"Logistic Regression\"\n",
    "    score_df.at[0,col] = score\n",
    "    \n",
    "    score=clf.score(X_test,y_test)\n",
    "    score_df.at[1,'method'] = \"Random Forest\"\n",
    "    score_df.at[1,col] = score\n",
    "    \n",
    "    score=nn.score(X_test,y_test)\n",
    "    score_df.at[2,'method'] = \"Neural Network\"\n",
    "    score_df.at[2,col] = score\n",
    "\n",
    "    \n",
    "    #Score for K-Neigh\n",
    "    for n in range (1,100):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "        neigh.fit(X_train, y_train) \n",
    "        if maxScore < neigh.score(X_test,y_test):\n",
    "            n1 = n\n",
    "            maxScore = neigh.score(X_test,y_test)\n",
    "\n",
    "    score_df.at[3,'method'] = \"K-Neighbors\"\n",
    "    score_df.at[3,col] = maxScore\n",
    "    \n",
    "My_Classifier (X_train, y_train,X_test, y_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def  My_Regression (X_train, y_train, X_test, y_test,it=0):\n",
    "    col=\"score \"+str(it)\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "\n",
    "    y_predicted = reg.predict(X_test)\n",
    "    score_df.at[4,'method'] = 'Linear Regression'\n",
    "    score_df.at[4,col] = r2_score(y_test, y_predicted)\n",
    "\n",
    "My_Regression(X_trainReg, y_trainReg,X_testReg, y_testReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 0.8524590163934426\n",
      "Random Forest 0.912568306010929\n",
      "Neural Network 0.8688524590163934\n",
      "K-Neighbors 0.8797814207650273\n",
      "Linear Regression 0.8158954153942367\n"
     ]
    }
   ],
   "source": [
    "def print_result(it=0):\n",
    "    #print(score_df)\n",
    "    for i,row in score_df.iterrows():\n",
    "        print (row[0], row[it+1])\n",
    "print_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['season', 'yr', 'mnth', 'holiday', 'weekday',\n",
    "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Specs      Score\n",
      "1           yr  95.836530\n",
      "2         mnth  56.264974\n",
      "0       season  31.621979\n",
      "7         temp  10.982432\n",
      "6   weathersit   8.975410\n",
      "8        atemp   8.965428\n",
      "4      weekday   4.769685\n",
      "10   windspeed   0.622985\n",
      "3      holiday   0.471047\n",
      "9          hum   0.410661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#apply SelectKBest class to extract top 8 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=8)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10378306 0.26669417 0.09278584 0.00520371 0.04772484 0.01571201\n",
      " 0.05245128 0.13072706 0.16823801 0.06216498 0.05451503]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(8).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using most effective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#feature_cols = ['instant','season', 'yr', 'mnth', 'holiday', 'weekday','workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "features1=['mnth','yr','season','temp','hum','weathersit','windspeed']\n",
    "X = df.loc[:, features1]\n",
    "y = df.cluster\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_trainReg, X_testReg, y_trainReg, y_testReg = train_test_split(X, yReg, test_size=0.25, random_state=42)\n",
    "\n",
    "My_Classifier(X_train, y_train,X_test, y_test, 1)\n",
    "\n",
    "My_Regression(X_trainReg, y_trainReg,X_testReg, y_testReg,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 0.8633879781420765\n",
      "Random Forest 0.9180327868852459\n",
      "Neural Network 0.8879617486338798\n",
      "K-Neighbors 0.9234972677595629\n",
      "Linear Regression 0.8266889860830545\n"
     ]
    }
   ],
   "source": [
    "print_result(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>score 0</th>\n",
       "      <th>score 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.863388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912568</td>\n",
       "      <td>0.918033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.887962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Neighbors</td>\n",
       "      <td>0.879781</td>\n",
       "      <td>0.923497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.815895</td>\n",
       "      <td>0.826689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                method   score 0   score 1\n",
       "0  Logistic Regression  0.852459  0.863388\n",
       "1        Random Forest  0.912568  0.918033\n",
       "2       Neural Network  0.868852  0.887962\n",
       "3          K-Neighbors  0.879781  0.923497\n",
       "4    Linear Regression  0.815895  0.826689"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network:  0.9016393442622951\n"
     ]
    }
   ],
   "source": [
    "nn= MLPClassifier(activation='relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'constant', solver='adam')\n",
    "nn.fit(X_train, y_train)\n",
    "score=nn.score(X_test,y_test)\n",
    "print('Neural Network: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
