{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualization library\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0        1       1   0     1        0        6           0           2   \n",
       "1        2       1   0     1        0        0           0           2   \n",
       "2        3       1   0     1        0        1           1           1   \n",
       "3        4       1   0     1        0        2           1           1   \n",
       "4        5       1   0     1        0        3           1           1   \n",
       "\n",
       "       temp     atemp       hum  windspeed   cnt cluster  \n",
       "0  0.344167  0.363625  0.805833   0.160446   985     low  \n",
       "1  0.363478  0.353739  0.696087   0.248539   801     low  \n",
       "2  0.196364  0.189405  0.437273   0.248309  1349     low  \n",
       "3  0.200000  0.212122  0.590435   0.160296  1562     low  \n",
       "4  0.226957  0.229270  0.436957   0.186900  1600     low  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_Preprocessed.csv\")\n",
    "df=df.drop(['dteday'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 489\n",
      "Test size 242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols = ['season','mnth','workingday','weathersit']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression SCORE:  0.6363636363636364\n",
      "Random Forest SCORE:  0.7727272727272727\n",
      "Neural Network:  0.7454545454545455\n",
      "K-Neighbors SCORE:  0.7318181818181818  N=  2\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def  My_Classifier (X_train, y_train, X_test, y_test):\n",
    "    maxScore =0\n",
    "    logreg = LogisticRegression()\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    nn = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "    #fit\n",
    "    logreg.fit(X_train, y_train)\n",
    "    clf.fit(X_train,y_train)\n",
    "    nn.fit(X_train, y_train)   \n",
    "\n",
    "    #Score\n",
    "    score=logreg.score(X_test,y_test)\n",
    "    print('Logistic Regression SCORE: ', score)\n",
    "    score=clf.score(X_test,y_test)\n",
    "    print('Random Forest SCORE: ', score)\n",
    "    score=nn.score(X_test,y_test)\n",
    "    print('Neural Network: ', score)\n",
    "    \n",
    "    #Score for K-Neigh\n",
    "    for n in range (1,100):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "        neigh.fit(X_train, y_train) \n",
    "        if maxScore < neigh.score(X_test,y_test):\n",
    "            n1 = n\n",
    "            maxScore = neigh.score(X_test,y_test)\n",
    "\n",
    "    print('K-Neighbors SCORE: ', maxScore, ' N= ', n1)\n",
    "    \n",
    "My_Classifier (X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['instant','season', 'yr', 'mnth', 'holiday', 'weekday',\n",
    "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Specs         Score\n",
      "0      instant  33491.883011\n",
      "3         mnth    142.379352\n",
      "2           yr    125.752042\n",
      "1       season     73.559153\n",
      "8         temp     20.697685\n",
      "9        atemp     17.442359\n",
      "7   weathersit     12.650286\n",
      "4      holiday      4.042412\n",
      "5      weekday      3.531337\n",
      "11   windspeed      1.342996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#apply SelectKBest class to extract top 8 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=8)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18886466 0.08259781 0.10211984 0.07552356 0.00804336 0.05150271\n",
      " 0.02120626 0.05946502 0.15150316 0.13995784 0.05648405 0.06273173]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(8).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 511\n",
      "Test size 220\n",
      "Logistic Regression SCORE:  0.6363636363636364\n",
      "Random Forest SCORE:  0.7545454545454545\n",
      "Neural Network:  0.7454545454545455\n",
      "K-Neighbors SCORE:  0.7318181818181818  N=  2\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "features1=['mnth','yr','season','temp','atemp','hum']\n",
    "X = df.loc[:, features1]\n",
    "y = df.cluster\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))\n",
    "My_Classifier(X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentativo di predizione temporale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 549\n",
      "Test size 182\n",
      "Logistic Regression SCORE:  0.46153846153846156\n",
      "Random Forest SCORE:  0.4340659340659341\n",
      "Neural Network:  0.1813186813186813\n",
      "K-Neighbors SCORE:  0.17582417582417584  N=  5\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "features1=['mnth','yr','season','temp','atemp','hum']\n",
    "\n",
    "X = df.loc[:, features1]\n",
    "mask_train = (df['instant'] < 550)\n",
    "mask_test = (df['instant'] >= 550)\n",
    "\n",
    "X_train=X.loc[mask_train]\n",
    "y_train=df.loc[mask_train].cluster\n",
    "X_test=X.loc[mask_test]\n",
    "y_test=df.loc[mask_test].cluster\n",
    "\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))\n",
    "My_Classifier(X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
