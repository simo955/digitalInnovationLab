{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualization library\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0        1       1   0     1        0        6           0           2   \n",
       "1        2       1   0     1        0        0           0           2   \n",
       "2        3       1   0     1        0        1           1           1   \n",
       "3        4       1   0     1        0        2           1           1   \n",
       "4        5       1   0     1        0        3           1           1   \n",
       "\n",
       "       temp     atemp       hum  windspeed   cnt cluster  \n",
       "0  0.344167  0.363625  0.805833   0.160446   985     low  \n",
       "1  0.363478  0.353739  0.696087   0.248539   801     low  \n",
       "2  0.196364  0.189405  0.437273   0.248309  1349     low  \n",
       "3  0.200000  0.212122  0.590435   0.160296  1562     low  \n",
       "4  0.226957  0.229270  0.436957   0.186900  1600     low  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_Preprocessed.csv\")\n",
    "df=df.drop(['dteday'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 511\n",
      "Test size 220\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols = ['season','mnth','workingday','weathersit']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression SCORE:  0.36818181818181817\n",
      "Random Forest SCORE:  0.4\n",
      "Neural Network:  0.4\n",
      "K-Neighbors SCORE:  0.43636363636363634  N=  20\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def  My_Classifier (X_train, y_train, X_test, y_test):\n",
    "    maxScore =0\n",
    "    logreg = LogisticRegression()\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    nn= MLPClassifier(activation= 'tanh', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'constant', solver= 'adam')\n",
    "    \n",
    "    #fit\n",
    "    logreg.fit(X_train, y_train)\n",
    "    clf.fit(X_train,y_train)\n",
    "    nn.fit(X_train, y_train)   \n",
    "\n",
    "    #Score\n",
    "    score=logreg.score(X_test,y_test)\n",
    "    print('Logistic Regression SCORE: ', score)\n",
    "    score=clf.score(X_test,y_test)\n",
    "    print('Random Forest SCORE: ', score)\n",
    "    score=nn.score(X_test,y_test)\n",
    "    print('Neural Network: ', score)\n",
    "    \n",
    "    #Score for K-Neigh\n",
    "    for n in range (1,100):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "        neigh.fit(X_train, y_train) \n",
    "        if maxScore < neigh.score(X_test,y_test):\n",
    "            n1 = n\n",
    "            maxScore = neigh.score(X_test,y_test)\n",
    "\n",
    "    print('K-Neighbors SCORE: ', maxScore, ' N= ', n1)\n",
    "    \n",
    "My_Classifier (X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['instant','season', 'yr', 'mnth', 'holiday', 'weekday',\n",
    "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Specs         Score\n",
      "0      instant  33491.883011\n",
      "3         mnth    142.379352\n",
      "2           yr    125.752042\n",
      "1       season     73.559153\n",
      "8         temp     20.697685\n",
      "9        atemp     17.442359\n",
      "7   weathersit     12.650286\n",
      "4      holiday      4.042412\n",
      "5      weekday      3.531337\n",
      "11   windspeed      1.342996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#apply SelectKBest class to extract top 8 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=8)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16731263 0.06605952 0.1077449  0.11975315 0.00811476 0.05254164\n",
      " 0.02371368 0.05508476 0.12238537 0.15069075 0.06736046 0.05923838]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(8).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "features1=['mnth','yr','season','temp','atemp','hum']\n",
    "X = df.loc[:, features1]\n",
    "y = df.cluster\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))\n",
    "My_Classifier(X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentativo di predizione temporale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 549\n",
      "Test size 182\n",
      "Logistic Regression SCORE:  0.46153846153846156\n",
      "Random Forest SCORE:  0.4340659340659341\n",
      "Neural Network:  0.1813186813186813\n",
      "K-Neighbors SCORE:  0.17582417582417584  N=  5\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "features1=['mnth','yr','season','temp','atemp','hum']\n",
    "\n",
    "X = df.loc[:, features1]\n",
    "mask_train = (df['instant'] < 550)\n",
    "mask_test = (df['instant'] >= 550)\n",
    "\n",
    "X_train=X.loc[mask_train]\n",
    "y_train=df.loc[mask_train].cluster\n",
    "X_test=X.loc[mask_test]\n",
    "y_test=df.loc[mask_test].cluster\n",
    "\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))\n",
    "My_Classifier(X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)], 'activation': ['tanh', 'relu'], 'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.05], 'learning_rate': ['constant', 'adaptive']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.438 (+/-0.076) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.691 (+/-0.059) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.425 (+/-0.068) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.689 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.442 (+/-0.040) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.689 (+/-0.043) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.548 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.681 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.464 (+/-0.060) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.656 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.477 (+/-0.111) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.634 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.472 (+/-0.051) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.703 (+/-0.057) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.454 (+/-0.069) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.699 (+/-0.035) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.505 (+/-0.099) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.699 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.477 (+/-0.070) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.703 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.446 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.659 (+/-0.088) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.407 (+/-0.090) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.654 (+/-0.060) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.436 (+/-0.102) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.681 (+/-0.055) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.366 (+/-0.078) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.695 (+/-0.079) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.462 (+/-0.071) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.699 (+/-0.067) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.431 (+/-0.098) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.708 (+/-0.023) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.458 (+/-0.137) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.626 (+/-0.013) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.429 (+/-0.023) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.646 (+/-0.033) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.384 (+/-0.035) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.708 (+/-0.018) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.438 (+/-0.096) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.703 (+/-0.051) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.462 (+/-0.116) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.687 (+/-0.034) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.458 (+/-0.020) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.708 (+/-0.057) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.423 (+/-0.116) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.648 (+/-0.012) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.407 (+/-0.084) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.669 (+/-0.035) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.66      0.68      0.67        57\n",
      "         low       0.94      0.78      0.85        58\n",
      "         mid       0.64      0.73      0.68        56\n",
      "   very_good       0.86      0.86      0.86        49\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       220\n",
      "   macro avg       0.77      0.76      0.77       220\n",
      "weighted avg       0.77      0.76      0.76       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test , clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 511\n",
      "Test size 220\n",
      "Logistic Regression SCORE:  0.6363636363636364\n",
      "Random Forest SCORE:  0.7818181818181819\n",
      "Neural Network:  0.7772727272727272\n",
      "K-Neighbors SCORE:  0.7318181818181818  N=  2\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "features1=['mnth','yr','season','temp','atemp','hum']\n",
    "X = df.loc[:, features1]\n",
    "y = df.cluster\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))\n",
    "My_Classifier(X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"labels ['dteday'] not contained in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-08d6bf4e958a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#df1 = df.drop(['season','dteday','yr','instant','atemp','hum','hum'], axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'season'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dteday'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'yr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'atemp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3692\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3694\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3138\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4387\u001b[0;31m                     'labels %s not contained in axis' % labels[mask])\n\u001b[0m\u001b[1;32m   4388\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"labels ['dteday'] not contained in axis\""
     ]
    }
   ],
   "source": [
    "#df1 = df.drop(['season','dteday','yr','instant','atemp','hum','hum'], axis=1)\n",
    "df1 = df.drop(['season','dteday','yr','atemp','hum','hum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
