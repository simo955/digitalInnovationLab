{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualization library\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0        1       1   0     1        0        6           0           2   \n",
       "1        2       1   0     1        0        0           0           2   \n",
       "2        3       1   0     1        0        1           1           1   \n",
       "3        4       1   0     1        0        2           1           1   \n",
       "4        5       1   0     1        0        3           1           1   \n",
       "\n",
       "       temp     atemp       hum  windspeed   cnt cluster  \n",
       "0  0.344167  0.363625  0.805833   0.160446   985     low  \n",
       "1  0.363478  0.353739  0.696087   0.248539   801     low  \n",
       "2  0.196364  0.189405  0.437273   0.248309  1349     low  \n",
       "3  0.200000  0.212122  0.590435   0.160296  1562     low  \n",
       "4  0.226957  0.229270  0.436957   0.186900  1600     low  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_Preprocessed2.csv\")\n",
    "df=df.drop(['dteday'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test set Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 548\n",
      "Test size 183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols = ['season', 'yr', 'mnth', 'holiday', 'weekday','workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster\n",
    "yReg= df.cnt\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_trainReg, X_testReg, y_trainReg, y_testReg = train_test_split(X, yReg, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Train size\",X_train.shape[0])\n",
    "print(\"Test size\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 0.8524590163934426\n",
      "Neural Network 0.8743169398907104\n",
      "K-Neighbors 0.8797814207650273\n",
      "Random Forest 0.9180327868852459\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#score df is later used for comparison between differen iteration\n",
    "score_df = pd.DataFrame(columns=[\"method\"])\n",
    "\n",
    "\n",
    "def  My_Classifier (X_train, y_train, X_test, y_test,it=0):\n",
    "    col=\"score \"+str(it)\n",
    "    score_df[col]=0.0\n",
    "    maxScore =0\n",
    "    \n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    clf=RandomForestClassifier(n_estimators=1000)\n",
    "    nn = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,), random_state=1)\n",
    "    \n",
    "    #fit\n",
    "    logreg.fit(X_train, y_train)\n",
    "    clf.fit(X_train,y_train)\n",
    "    nn.fit(X_train, y_train)   \n",
    "\n",
    "    #Score\n",
    "    score=logreg.score(X_test,y_test)\n",
    "    score_df.at[0,'method'] = \"Logistic Regression\"\n",
    "    score_df.at[0,col] = score\n",
    "    \n",
    "    score=clf.score(X_test,y_test)\n",
    "    score_df.at[1,'method'] = \"Random Forest\"\n",
    "    score_df.at[1,col] = score\n",
    "    \n",
    "    score=nn.score(X_test,y_test)\n",
    "    score_df.at[2,'method'] = \"Neural Network\"\n",
    "    score_df.at[2,col] = score\n",
    "\n",
    "    \n",
    "    #Score for K-Neigh\n",
    "    for n in range (1,100):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "        neigh.fit(X_train, y_train) \n",
    "        if maxScore < neigh.score(X_test,y_test):\n",
    "            n1 = n\n",
    "            maxScore = neigh.score(X_test,y_test)\n",
    "\n",
    "    score_df.at[3,'method'] = \"K-Neighbors\"\n",
    "    score_df.at[3,col] = maxScore\n",
    "\n",
    "    #printing results\n",
    "    score_df.sort_values(by=[col],inplace=True)\n",
    "    for i,row in score_df.iterrows():\n",
    "        print (row[0], row[1])\n",
    "    \n",
    "My_Classifier (X_train, y_train,X_test, y_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def  My_Regression (X_train, y_train, X_test, y_test,it=0):\n",
    "    col=\"score \"+str(it)\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "\n",
    "    y_predicted = reg.predict(X_test)\n",
    "    score_df.at[4,'method'] = 'Linear Regression'\n",
    "    score_df.at[4,col] = r2_score(y_test, y_predicted)\n",
    "\n",
    "My_Regression(X_trainReg, y_trainReg,X_testReg, y_testReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['season', 'yr', 'mnth', 'holiday', 'weekday',\n",
    "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "X = df.loc[:, feature_cols]\n",
    "y = df.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Specs      Score\n",
      "1           yr  95.836530\n",
      "2         mnth  56.264974\n",
      "0       season  31.621979\n",
      "7         temp  10.982432\n",
      "6   weathersit   8.975410\n",
      "8        atemp   8.965428\n",
      "4      weekday   4.769685\n",
      "10   windspeed   0.622985\n",
      "3      holiday   0.471047\n",
      "9          hum   0.410661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#apply SelectKBest class to extract top 8 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=8)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11071159 0.27180533 0.0990671  0.00567809 0.04468201 0.02085231\n",
      " 0.04540647 0.16449742 0.10254677 0.07895073 0.05580219]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(8).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using most effective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression 0.8158954153942367\n",
      "Logistic Regression 0.8524590163934426\n",
      "Neural Network 0.8743169398907104\n",
      "Random Forest 0.9180327868852459\n",
      "K-Neighbors 0.8797814207650273\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#feature_cols = ['instant','season', 'yr', 'mnth', 'holiday', 'weekday','workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "features1=['mnth','yr','season','temp','hum','weathersit','windspeed']\n",
    "X = df.loc[:, features1]\n",
    "y = df.cluster\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_trainReg, X_testReg, y_trainReg, y_testReg = train_test_split(X, yReg, test_size=0.25, random_state=42)\n",
    "\n",
    "My_Classifier(X_train, y_train,X_test, y_test, 1)\n",
    "\n",
    "My_Regression(X_trainReg, y_trainReg,X_testReg, y_testReg,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>score 0</th>\n",
       "      <th>score 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.815895</td>\n",
       "      <td>0.826689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.863388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.874317</td>\n",
       "      <td>0.874317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.912568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Neighbors</td>\n",
       "      <td>0.879781</td>\n",
       "      <td>0.923497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                method   score 0   score 1\n",
       "4    Linear Regression  0.815895  0.826689\n",
       "0  Logistic Regression  0.852459  0.863388\n",
       "2       Neural Network  0.874317  0.874317\n",
       "1        Random Forest  0.918033  0.912568\n",
       "3          K-Neighbors  0.879781  0.923497"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network:  0.8907103825136612\n"
     ]
    }
   ],
   "source": [
    "nn= MLPClassifier(activation='relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'constant', solver='adam')\n",
    "nn.fit(X_train, y_train)\n",
    "score=nn.score(X_test,y_test)\n",
    "print('Neural Network: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
